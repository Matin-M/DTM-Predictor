{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNoSyR_YZJDo",
        "outputId": "e7fdd43a-8a69-43d5-877c-c49caa23dc10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymongo[srv] in /opt/conda/lib/python3.10/site-packages (4.3.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from pymongo[srv]) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "#Import SDK\n",
        "!python -m pip install \"pymongo[srv]\"\n",
        "from pymongo import MongoClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "fscaJC9EbHwq"
      },
      "outputs": [],
      "source": [
        "#Define a function that returns our Atlas client for use\n",
        "def get_database_client():\n",
        " \n",
        "   # Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
        "   CONNECTION_STRING = \"mongodb+srv://general_user:Fancy_Password1@cluster0.cc9gcm8.mongodb.net/db\"\n",
        " \n",
        "   # Create a connection using MongoClient. You can import MongoClient or use pymongo.MongoClient\n",
        "   client = MongoClient(CONNECTION_STRING)\n",
        "\n",
        "   return client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilcIE8jgeG90",
        "outputId": "a4c19603-5e43-43f6-ca7d-0234cb814b34"
      },
      "outputs": [],
      "source": [
        "client = get_database_client()\n",
        "db = client.db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.3.23)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (67.6.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.28.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.2)\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Requirement already satisfied: smbprotocol in /opt/conda/lib/python3.10/site-packages (1.10.1)\n",
            "Requirement already satisfied: cryptography>=2.0 in /opt/conda/lib/python3.10/site-packages (from smbprotocol) (39.0.2)\n",
            "Requirement already satisfied: pyspnego in /opt/conda/lib/python3.10/site-packages (from smbprotocol) (0.8.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.0->smbprotocol) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.0->smbprotocol) (2.21)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install nltk\n",
        "pip install spacy\n",
        "python -m spacy download en\n",
        "python -m spacy download en_core_web_sm\n",
        "pip install smbprotocol\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "\n",
        "#Assets\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['quick', 'brown', 'fox', 'jump', 'lazi', 'dog']\n"
          ]
        }
      ],
      "source": [
        "stop_words = stopwords.words('english')\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def custom_preprocessor(text):\n",
        "    # Remove URLs starting with http or https\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "    \n",
        "    # Remove URLs starting with www.\n",
        "    text = re.sub(r'www\\.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "\n",
        "    # Remove newline characters\n",
        "    text = text.replace('\\n', ' ')\n",
        "    \n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    \n",
        "    # Remove non-English characters and special symbols\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    \n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Custom tokenizer that lemmatizes and removes punctuation\n",
        "def custom_tokenizer(text):\n",
        "    # Process the text with the loaded model\n",
        "    doc = nlp(text)\n",
        "    \n",
        "    # Extract the stemmed form of each token, excluding stopwords and punctuation\n",
        "    stemmed_tokens = [stemmer.stem(token.text) for token in doc if not token.is_stop and not token.is_punct]\n",
        "    return stemmed_tokens\n",
        "\n",
        "\n",
        "# Test the custom tokenizer\n",
        "test_string = \"The quick brown foxes are jumping over the lazy dogs.\"\n",
        "print(custom_tokenizer(custom_preprocessor(test_string)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         DATE   TIME  DIR\n",
            "0  2017.03.13  16:30    0\n",
            "1  2017.03.13  17:30    1\n",
            "2  2017.03.13  18:30    0\n",
            "3  2017.03.13  19:30    1\n",
            "4  2017.03.13  20:30    1\n",
            "         DATE   TIME  DIR\n",
            "0  2016.03.16  19:30    1\n",
            "1  2016.03.16  20:30    1\n",
            "2  2016.03.17  12:30    1\n",
            "3  2016.03.17  13:30    1\n",
            "4  2016.03.17  14:30    1\n"
          ]
        }
      ],
      "source": [
        "#Get training dataframes from SMB server\n",
        "import pandas as pd\n",
        "#Open hourly stock data\n",
        "cols = [\"DATE\", \"TIME\", \"OPEN\", \"HIGH\", \"LOW\", \"CLOSE\", \"VOLUME\"]\n",
        "amazon_hourly_stock_quote_data = pd.read_csv('https://raw.githubusercontent.com/Matin-M/StockDirectionPrediction/data-labeling/Data/Stock/AMAZON60.csv', names=cols, header=None)\n",
        "apple_hourly_stock_quote_data = pd.read_csv('https://raw.githubusercontent.com/Matin-M/StockDirectionPrediction/data-labeling/Data/Stock/APPLE60.csv', names=cols, header=None)\n",
        "\n",
        "def generate_hourly_stock_data(hourly_stock_quote_data):\n",
        "    stock_data = pd.DataFrame()\n",
        "    stock_data[\"DATE\"] = []\n",
        "    stock_data[\"TIME\"] = []\n",
        "    stock_data[\"DIR\"] = []\n",
        "\n",
        "    for idx, row in hourly_stock_quote_data.iterrows():\n",
        "        if idx < len(hourly_stock_quote_data) - 1:\n",
        "            nitem = hourly_stock_quote_data[idx+1:idx+2]\n",
        "            direction = 1 if float(nitem[\"OPEN\"]) <= float(nitem[\"CLOSE\"]) else 0\n",
        "            stock_data.loc[len(stock_data.index)] = [row[\"DATE\"], row[\"TIME\"], direction]\n",
        "\n",
        "    return stock_data\n",
        "\n",
        "amazon_stock_data = generate_hourly_stock_data(amazon_hourly_stock_quote_data)\n",
        "print(amazon_stock_data.head())\n",
        "apple_stock_data = generate_hourly_stock_data(apple_hourly_stock_quote_data)\n",
        "print(apple_stock_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "IhJ1hZQd7qCF"
      },
      "outputs": [],
      "source": [
        "total = db.news.find({\"language\": \"english\"})\n",
        "apple_news = db.news.find({\"$and\": [{ \"language\": \"english\"}, {\"$or\": [ { \"title\": {\"$regex\": 'apple', \"$options\": 'i'}}, { \"title\": {\"$regex\": 'aapl', \"$options\": 'i'}}, { \"text\": {\"$regex\": 'apple', \"$options\": 'i'}}, { \"text\": {\"$regex\": 'aapl', \"$options\": 'i'}} ] }]}, {\"text\": 1, \"published\": 1})\n",
        "amazon_news = db.news.find({\"$and\": [{ \"language\": \"english\"}, {\"$or\": [ { \"title\": {\"$regex\": 'amazon', \"$options\": 'i'}}, { \"title\": {\"$regex\": 'amzn', \"$options\": 'i'}}, { \"text\": {\"$regex\": 'amazon', \"$options\": 'i'}}, { \"text\": {\"$regex\": 'amzn', \"$options\": 'i'}} ] }]}, {\"text\": 1, \"published\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple count: 7957\n",
            "Amazon count: 2159\n"
          ]
        }
      ],
      "source": [
        "# Get length of news\n",
        "apple_count = len(list(apple_news))\n",
        "amazon_count = len(list(amazon_news))\n",
        "\n",
        "print(\"Apple count:\", apple_count)\n",
        "print(\"Amazon count:\", amazon_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "\n",
        "def round_time(time):\n",
        "  # round up to the nearest hour (minutes need to be 30)\n",
        "  hour = time.hour\n",
        "\n",
        "  if time.minute > 30:\n",
        "    # hour = time.hour + 1\n",
        "    time += timedelta(hours=1)\n",
        "    if hour == 24:\n",
        "      hour = 0\n",
        "\n",
        "  news_date = f\"{time.year}.{'%02d' % time.month}.{'%02d' % time.day}\"\n",
        "  return f\"{'%02d' % time.hour}:30\", news_date\n",
        "\n",
        "def generate_company_dir(company_news, stock_data):\n",
        "    company_dir = pd.DataFrame()\n",
        "    company_dir[\"IDX\"] = []\n",
        "    company_dir[\"DIR\"] = []\n",
        "    company_dir[\"TEXT\"] = []\n",
        "\n",
        "    for idx, news in enumerate(company_news):\n",
        "        date = datetime.fromisoformat(news[\"published\"])\n",
        "        news_time, news_date = round_time(date)\n",
        "        stock_dir = stock_data.loc[(stock_data[\"DATE\"] == news_date) & (stock_data[\"TIME\"] == news_time)]\n",
        "\n",
        "        if stock_dir.shape[0] > 0:\n",
        "            company_dir.loc[len(company_dir.index)] = [idx, stock_dir['DIR'].values[0], news[\"text\"]]\n",
        "        else:\n",
        "            #this means the stock market was closed and need to check for the next time it is open\n",
        "            [hour, mins] = news_time.split(':')\n",
        "            [year, month, day] = news_date.split(\".\")\n",
        "            date = datetime(int(year), int(month), int(day), int(hour), int(mins), 0, 0)\n",
        "            # loop through and make sure it doesnt hit the last index\n",
        "            max_datetime = datetime(2019, 2, 1, 19, 30, 0, 0)\n",
        "            \n",
        "            while max_datetime > date:\n",
        "                # increment date\n",
        "                date += timedelta(hours=1)\n",
        "                news_time, news_date = round_time(date)\n",
        "                stock_dir = stock_data.loc[(stock_data[\"DATE\"] == news_date) & (stock_data[\"TIME\"] == news_time)]\n",
        "                \n",
        "                if stock_dir.shape[0] > 0:\n",
        "                    company_dir.loc[len(company_dir.index)] = [idx, stock_dir['DIR'].values[0], news[\"text\"]]\n",
        "                    break\n",
        "\n",
        "    return company_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "amazon_dir = generate_company_dir(amazon_news, amazon_stock_data)\n",
        "apple_dir = generate_company_dir(apple_news, apple_stock_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1902\n",
            "   IDX  DIR                                               TEXT\n",
            "0    0    1  © Reuters. US STOCKS-Wall St edges higher afte...\n",
            "1    1    1  Facebook reports positive earnings despite rec...\n",
            "2    2    1  The stock market continued to reward positive ...\n",
            "3    5    1  5 Top Stocks to Own This February Tirthankar C...\n",
            "4    6    1  The major stock indexes posted uneven gains ea...\n",
            "6996\n",
            "   IDX  DIR                                               TEXT\n",
            "0    1    1  © Reuters. US STOCKS-Wall St edges higher afte...\n",
            "1    2    1  https://www.businessinsider.com/coolest-apple-...\n",
            "2    3    1  80% + correct on my stocks prediction post 80%...\n",
            "3    4    1  This copy is for your personal, non-commercial...\n",
            "4    5    1  Posted by Ed Jones on Feb 1st, 2019 // No Comm...\n"
          ]
        }
      ],
      "source": [
        "print(len(amazon_dir))\n",
        "print(amazon_dir.head())\n",
        "\n",
        "print(len(apple_dir))\n",
        "print(apple_dir.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tHkuQGXRTLi",
        "outputId": "58c237e9-c54c-45c3-9075-c258f84a431c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# 1-gram/term vectorization\n",
        "term_vectorizer = CountVectorizer(ngram_range=(1,1), strip_accents=\"unicode\", preprocessor=custom_preprocessor, tokenizer=custom_tokenizer, min_df=0.01)\n",
        "term_matrix = term_vectorizer.fit_transform(apple_dir['TEXT'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6996, 2982)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aal</th>\n",
              "      <th>aap</th>\n",
              "      <th>aapl</th>\n",
              "      <th>aaplo</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abc</th>\n",
              "      <th>abil</th>\n",
              "      <th>abl</th>\n",
              "      <th>abroad</th>\n",
              "      <th>absolut</th>\n",
              "      <th>...</th>\n",
              "      <th>york</th>\n",
              "      <th>yorkbas</th>\n",
              "      <th>young</th>\n",
              "      <th>youtub</th>\n",
              "      <th>yy</th>\n",
              "      <th>zack</th>\n",
              "      <th>zackscom</th>\n",
              "      <th>zero</th>\n",
              "      <th>zone</th>\n",
              "      <th>zuckerberg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2982 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aal  aap  aapl  aaplo  abandon  abc  abil  abl  abroad  absolut  ...  york  \\\n",
              "0    0    0     0      1        0    0     0    0       0        0  ...     0   \n",
              "1    0    0     1      0        0    0     0    0       0        0  ...     3   \n",
              "2    0    0     1      0        0    0     0    0       0        0  ...     0   \n",
              "3    0    0     1      0        0    0     0    0       0        0  ...     0   \n",
              "4    0    0     4      0        0    0     0    0       0        0  ...     0   \n",
              "\n",
              "   yorkbas  young  youtub  yy  zack  zackscom  zero  zone  zuckerberg  \n",
              "0        0      0       0   0     0         0     0     0           0  \n",
              "1        0      0       0   0     0         0     0     0           0  \n",
              "2        0      0       0   0     0         0     0     0           0  \n",
              "3        0      0       0   0     0         0     0     0           0  \n",
              "4        0      0       0   0     0         0     0     0           0  \n",
              "\n",
              "[5 rows x 2982 columns]"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Show the resulting matrix\n",
        "print(term_matrix.toarray().shape)\n",
        "# Get the first 20 words in the vocabulary\n",
        "feature_names = term_vectorizer.get_feature_names_out()\n",
        "# Construct the DataFrame\n",
        "term_df = pd.DataFrame(term_matrix.toarray(), columns=feature_names)\n",
        "term_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DoZDRRnSNCB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7957, 2945)\n"
          ]
        }
      ],
      "source": [
        "# Example usage with CountVectorizer for bigrams\n",
        "bigram_vectorizer = CountVectorizer(ngram_range=(2,2), strip_accents=\"unicode\", preprocessor=custom_preprocessor, tokenizer=custom_tokenizer, min_df=0.01)\n",
        "bigram_matrix = bigram_vectorizer.fit_transform(apple_text)\n",
        "print(bigram_matrix.toarray().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7957, 2945)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aapl amazon</th>\n",
              "      <th>aapl appl</th>\n",
              "      <th>aapl base</th>\n",
              "      <th>aapl facebook</th>\n",
              "      <th>aapl free</th>\n",
              "      <th>aapl iphon</th>\n",
              "      <th>aapl microsoft</th>\n",
              "      <th>aapl open</th>\n",
              "      <th>aapl post</th>\n",
              "      <th>aapl profit</th>\n",
              "      <th>...</th>\n",
              "      <th>yield benchmark</th>\n",
              "      <th>yield exdividend</th>\n",
              "      <th>yield rise</th>\n",
              "      <th>yield year</th>\n",
              "      <th>york time</th>\n",
              "      <th>zack consensu</th>\n",
              "      <th>zack invest</th>\n",
              "      <th>zack rank</th>\n",
              "      <th>zack research</th>\n",
              "      <th>zack stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2945 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aapl amazon  aapl appl  aapl base  aapl facebook  aapl free  aapl iphon  \\\n",
              "0            0          0          0              0          0           0   \n",
              "1            0          0          0              0          0           0   \n",
              "2            0          0          0              0          0           0   \n",
              "3            0          0          0              0          0           0   \n",
              "4            0          0          0              0          0           0   \n",
              "\n",
              "   aapl microsoft  aapl open  aapl post  aapl profit  ...  yield benchmark  \\\n",
              "0               0          0          0            0  ...                0   \n",
              "1               0          0          0            0  ...                0   \n",
              "2               0          0          0            0  ...                0   \n",
              "3               0          0          0            0  ...                0   \n",
              "4               0          0          0            0  ...                0   \n",
              "\n",
              "   yield exdividend  yield rise  yield year  york time  zack consensu  \\\n",
              "0                 0           0           0          0              0   \n",
              "1                 0           0           0          0              0   \n",
              "2                 0           0           0          0              0   \n",
              "3                 0           0           0          0              0   \n",
              "4                 0           0           0          0              0   \n",
              "\n",
              "   zack invest  zack rank  zack research  zack stock  \n",
              "0            0          0              0           0  \n",
              "1            0          0              0           0  \n",
              "2            0          0              0           0  \n",
              "3            0          0              0           0  \n",
              "4            0          0              0           0  \n",
              "\n",
              "[5 rows x 2945 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show the resulting matrix\n",
        "print(bigram_matrix.toarray().shape)\n",
        "# Get the first 20 words in the vocabulary\n",
        "bigram_feature_names = bigram_vectorizer.get_feature_names_out()\n",
        "# Construct the DataFrame\n",
        "bigram_df = pd.DataFrame(bigram_matrix.toarray(), columns=bigram_feature_names)\n",
        "bigram_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "import smbclient\n",
        "\n",
        "smb_server_ip = os.environ['SMB_SERVER_IP']\n",
        "smb_server_port = int(os.environ['SMB_SERVER_PORT'])\n",
        "smb_username = os.environ['SMB_USERNAME']\n",
        "smb_password = os.environ['SMB_PASSWORD']\n",
        "smb_share_name = os.environ['SMB_SHARE_NAME']\n",
        "\n",
        "# Set the SMB client configuration\n",
        "smbclient.ClientConfig(username=smb_username, password=smb_password)\n",
        "\n",
        "def save_dataframe_to_smb_server(df, remote_file_path):\n",
        "    # Create a temporary file to store the compressed CSV\n",
        "    with tempfile.NamedTemporaryFile(mode='w+', suffix='.csv.gz', delete=False) as temp_file:\n",
        "        df.to_csv(temp_file.name, index=False, compression='gzip')\n",
        "        temp_file_path = temp_file.name\n",
        "\n",
        "    # Create the full remote path\n",
        "    remote_path = f\"\\\\\\\\{smb_server_ip}\\\\{smb_share_name}\\\\{remote_file_path}\"\n",
        "\n",
        "    # Upload the temporary compressed CSV file to the SMB share\n",
        "    with open(temp_file_path, 'rb') as local_file:\n",
        "        with smbclient.open_file(remote_path, mode='wb') as remote_file:\n",
        "            remote_file.write(local_file.read())\n",
        "\n",
        "    # Delete the temporary file\n",
        "    os.unlink(temp_file_path)\n",
        "\n",
        "# Save both DataFrames to the SMB server\n",
        "save_dataframe_to_smb_server(term_df, 'term_df_compressed.csv.gz')\n",
        "save_dataframe_to_smb_server(bigram_df, 'bigram_df_compressed.csv.gz')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
